{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b865c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Greenhouse Gas Analytics - Data Exploration\n",
    "# Notebook 01: Comprehensive Data Exploration and Initial Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set styling\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üåç Greenhouse Gas Analytics - Data Exploration\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ## 1. Data Loading and Initial Inspection\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('../data/raw/Methane_final.csv')\n",
    "    print(f\"‚úÖ Data loaded successfully!\")\n",
    "    print(f\"üìä Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Dataset not found. Creating sample data for demonstration...\")\n",
    "    \n",
    "    # Create comprehensive sample data\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    countries = ['China', 'India', 'USA', 'Indonesia', 'Brazil', 'Nigeria', 'Russia', \n",
    "                'Mexico', 'Iran', 'Germany', 'Turkey', 'Canada', 'Australia', \n",
    "                'Argentina', 'Algeria', 'Kazakhstan', 'Uzbekistan', 'Thailand',\n",
    "                'Malaysia', 'Venezuela', 'Saudi Arabia', 'Pakistan', 'Egypt',\n",
    "                'Ukraine', 'Bangladesh', 'Vietnam', 'Philippines', 'Myanmar',\n",
    "                'Poland', 'South Africa']\n",
    "    \n",
    "    regions = {\n",
    "        'China': 'Asia', 'India': 'Asia', 'USA': 'North America', 'Indonesia': 'Asia',\n",
    "        'Brazil': 'South America', 'Nigeria': 'Africa', 'Russia': 'Europe',\n",
    "        'Mexico': 'North America', 'Iran': 'Asia', 'Germany': 'Europe',\n",
    "        'Turkey': 'Europe', 'Canada': 'North America', 'Australia': 'Oceania',\n",
    "        'Argentina': 'South America', 'Algeria': 'Africa', 'Kazakhstan': 'Asia',\n",
    "        'Uzbekistan': 'Asia', 'Thailand': 'Asia', 'Malaysia': 'Asia',\n",
    "        'Venezuela': 'South America', 'Saudi Arabia': 'Asia', 'Pakistan': 'Asia',\n",
    "        'Egypt': 'Africa', 'Ukraine': 'Europe', 'Bangladesh': 'Asia',\n",
    "        'Vietnam': 'Asia', 'Philippines': 'Asia', 'Myanmar': 'Asia',\n",
    "        'Poland': 'Europe', 'South Africa': 'Africa'\n",
    "    }\n",
    "    \n",
    "    types = ['Agriculture', 'Energy', 'Waste', 'Other']\n",
    "    segments = ['Livestock', 'Oil & Gas', 'Landfills', 'Rice Cultivation', \n",
    "               'Coal Mining', 'Bioenergy', 'Gas pipelines', 'Onshore oil', 'Total']\n",
    "    base_years = ['2019-2021', '2020-2021', '2022', '2021', '2019']\n",
    "    \n",
    "    data = []\n",
    "    for country in countries:\n",
    "        for _ in range(np.random.randint(15, 25)):  # Variable entries per country\n",
    "            emission_base = np.random.exponential(50) + np.random.normal(20, 30)\n",
    "            data.append({\n",
    "                'region': regions[country],\n",
    "                'country': country,\n",
    "                'emissions': max(0, emission_base),\n",
    "                'type': np.random.choice(types),\n",
    "                'segment': np.random.choice(segments),\n",
    "                'reason': 'All',\n",
    "                'baseYear': np.random.choice(base_years)\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"üìä Sample dataset created with shape: {df.shape}\")\n",
    "\n",
    "# ## 2. Basic Data Information\n",
    "\n",
    "print(\"\\nüìã DATASET OVERVIEW\")\n",
    "print(\"=\"*30)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nüìä MISSING VALUES:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Percentage': missing_percent\n",
    "}).sort_values('Percentage', ascending=False)\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# ## 3. Statistical Summary\n",
    "\n",
    "print(f\"\\nüìà STATISTICAL SUMMARY:\")\n",
    "print(\"=\"*30)\n",
    "print(df.describe())\n",
    "\n",
    "# ## 4. Categorical Variables Analysis\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è CATEGORICAL VARIABLES:\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col.upper()}:\")\n",
    "    value_counts = df[col].value_counts()\n",
    "    print(f\"  Unique values: {df[col].nunique()}\")\n",
    "    print(f\"  Top 5 values:\")\n",
    "    for val, count in value_counts.head().items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"    {val}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# ## 5. Numerical Variables Analysis\n",
    "\n",
    "print(f\"\\nüî¢ NUMERICAL VARIABLES:\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Clean emissions data\n",
    "df['emissions'] = pd.to_numeric(df['emissions'], errors='coerce')\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numerical_cols:\n",
    "    print(f\"\\n{col.upper()}:\")\n",
    "    print(f\"  Mean: {df[col].mean():.2f}\")\n",
    "    print(f\"  Median: {df[col].median():.2f}\")\n",
    "    print(f\"  Std: {df[col].std():.2f}\")\n",
    "    print(f\"  Min: {df[col].min():.2f}\")\n",
    "    print(f\"  Max: {df[col].max():.2f}\")\n",
    "    print(f\"  25th percentile: {df[col].quantile(0.25):.2f}\")\n",
    "    print(f\"  75th percentile: {df[col].quantile(0.75):.2f}\")\n",
    "\n",
    "# ## 6. Data Quality Assessment\n",
    "\n",
    "print(f\"\\nüîç DATA QUALITY ASSESSMENT:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicates}\")\n",
    "\n",
    "# Check for negative emissions\n",
    "if 'emissions' in df.columns:\n",
    "    negative_emissions = (df['emissions'] < 0).sum()\n",
    "    print(f\"Negative emissions: {negative_emissions}\")\n",
    "    \n",
    "    # Check for zero emissions\n",
    "    zero_emissions = (df['emissions'] == 0).sum()\n",
    "    print(f\"Zero emissions: {zero_emissions}\")\n",
    "    \n",
    "    # Check for outliers using IQR method\n",
    "    Q1 = df['emissions'].quantile(0.25)\n",
    "    Q3 = df['emissions'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = ((df['emissions'] < lower_bound) | (df['emissions'] > upper_bound)).sum()\n",
    "    print(f\"Potential outliers (IQR method): {outliers}\")\n",
    "\n",
    "# ## 7. Visual Data Exploration\n",
    "\n",
    "print(f\"\\nüìä CREATING VISUALIZATIONS...\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Set up matplotlib for better visualization\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "# 1. Emissions Distribution\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "df['emissions'].hist(bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Methane Emissions', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Emissions (Mt CO‚ÇÇe)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Emissions by Region\n",
    "plt.subplot(3, 2, 2)\n",
    "regional_emissions = df.groupby('region')['emissions'].sum().sort_values(ascending=True)\n",
    "regional_emissions.plot(kind='barh', color='lightcoral')\n",
    "plt.title('Total Emissions by Region', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Total Emissions (Mt CO‚ÇÇe)')\n",
    "plt.tight_layout()\n",
    "\n",
    "# 3. Emissions by Type\n",
    "plt.subplot(3, 2, 3)\n",
    "type_emissions = df.groupby('type')['emissions'].sum()\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(type_emissions)))\n",
    "type_emissions.plot(kind='pie', autopct='%1.1f%%', colors=colors)\n",
    "plt.title('Emissions Distribution by Type', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('')\n",
    "\n",
    "# 4. Top 10 Countries\n",
    "plt.subplot(3, 2, 4)\n",
    "top_countries = df.groupby('country')['emissions'].sum().sort_values(ascending=False).head(10)\n",
    "top_countries.plot(kind='bar', color='gold', alpha=0.8)\n",
    "plt.title('Top 10 Emitting Countries', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Emissions (Mt CO‚ÇÇe)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 5. Emissions by Segment\n",
    "plt.subplot(3, 2, 5)\n",
    "segment_emissions = df.groupby('segment')['emissions'].sum().sort_values(ascending=False)\n",
    "segment_emissions.plot(kind='bar', color='lightgreen', alpha=0.8)\n",
    "plt.title('Emissions by Segment', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Emissions (Mt CO‚ÇÇe)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 6. Box plot for emissions by type\n",
    "plt.subplot(3, 2, 6)\n",
    "df.boxplot(column='emissions', by='type', ax=plt.gca())\n",
    "plt.title('Emissions Distribution by Type (Box Plot)', fontsize=14, fontweight='bold')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "plt.xlabel('Emission Type')\n",
    "plt.ylabel('Emissions (Mt CO‚ÇÇe)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ## 8. Interactive Plotly Visualizations\n",
    "\n",
    "print(f\"\\nüé® CREATING INTERACTIVE VISUALIZATIONS...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Interactive Regional Analysis\n",
    "fig_regional = px.treemap(\n",
    "    df.groupby(['region', 'country'])['emissions'].sum().reset_index(),\n",
    "    path=['region', 'country'],\n",
    "    values='emissions',\n",
    "    title='Hierarchical View: Emissions by Region and Country',\n",
    "    color='emissions',\n",
    "    color_continuous_scale='Reds'\n",
    ")\n",
    "fig_regional.update_layout(height=600)\n",
    "fig_regional.show()\n",
    "\n",
    "# 2. Interactive Scatter Plot\n",
    "country_summary = df.groupby('country').agg({\n",
    "    'emissions': 'sum',\n",
    "    'region': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "fig_scatter = px.scatter(\n",
    "    country_summary,\n",
    "    x=range(len(country_summary)),\n",
    "    y='emissions',\n",
    "    color='region',\n",
    "    size='emissions',\n",
    "    hover_name='country',\n",
    "    title='Country Emissions Overview',\n",
    "    labels={'x': 'Country Index', 'y': 'Total Emissions (Mt CO‚ÇÇe)'}\n",
    ")\n",
    "fig_scatter.update_layout(height=500)\n",
    "fig_scatter.show()\n",
    "\n",
    "# 3. Sunburst Chart\n",
    "fig_sunburst = px.sunburst(\n",
    "    df.groupby(['region', 'type', 'segment'])['emissions'].sum().reset_index(),\n",
    "    path=['region', 'type', 'segment'],\n",
    "    values='emissions',\n",
    "    title='Multi-level Emissions Breakdown'\n",
    ")\n",
    "fig_sunburst.update_layout(height=600)\n",
    "fig_sunburst.show()\n",
    "\n",
    "# ## 9. Correlation Analysis\n",
    "\n",
    "print(f\"\\nüîó CORRELATION ANALYSIS:\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Create dummy variables for categorical analysis\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "categorical_cols = ['region', 'type', 'segment']\n",
    "for col in categorical_cols:\n",
    "    dummies = pd.get_dummies(df_encoded[col], prefix=col)\n",
    "    df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "\n",
    "# Select numeric columns for correlation\n",
    "numeric_cols = df_encoded.select_dtypes(include=[np.number]).columns\n",
    "corr_matrix = df_encoded[numeric_cols].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix))\n",
    "sns.heatmap(corr_matrix, \n",
    "            annot=True, \n",
    "            cmap='RdYlBu_r', \n",
    "            center=0,\n",
    "            mask=mask,\n",
    "            square=True,\n",
    "            fmt='.2f')\n",
    "plt.title('Correlation Matrix of Encoded Variables', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ## 10. Time Series Analysis (if applicable)\n",
    "\n",
    "if 'baseYear' in df.columns:\n",
    "    print(f\"\\nüìÖ TEMPORAL ANALYSIS:\")\n",
    "    print(\"=\"*25)\n",
    "    \n",
    "    # Extract year information\n",
    "    df['year'] = df['baseYear'].str.extract('(\\d{4})').astype(float)\n",
    "    \n",
    "    if df['year'].notna().sum() > 0:\n",
    "        # Yearly emissions trend\n",
    "        yearly_emissions = df.groupby('year')['emissions'].agg(['sum', 'mean', 'count']).reset_index()\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "        \n",
    "        # Total emissions by year\n",
    "        ax1.plot(yearly_emissions['year'], yearly_emissions['sum'], \n",
    "                marker='o', linewidth=2, markersize=8, color='red', alpha=0.8)\n",
    "        ax1.set_title('Total Methane Emissions Over Time', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Year')\n",
    "        ax1.set_ylabel('Total Emissions (Mt CO‚ÇÇe)')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Average emissions by year\n",
    "        ax2.plot(yearly_emissions['year'], yearly_emissions['mean'], \n",
    "                marker='s', linewidth=2, markersize=8, color='blue', alpha=0.8)\n",
    "        ax2.set_title('Average Methane Emissions per Record Over Time', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('Year')\n",
    "        ax2.set_ylabel('Average Emissions (Mt CO‚ÇÇe)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Sector trends over time\n",
    "        if len(df['year'].unique()) > 1:\n",
    "            sector_trends = df.groupby(['year', 'type'])['emissions'].sum().reset_index()\n",
    "            \n",
    "            fig_trends = px.line(\n",
    "                sector_trends,\n",
    "                x='year',\n",
    "                y='emissions',\n",
    "                color='type',\n",
    "                markers=True,\n",
    "                title='Emissions Trends by Sector Over Time',\n",
    "                labels={'emissions': 'Emissions (Mt CO‚ÇÇe)', 'year': 'Year'}\n",
    "            )\n",
    "            fig_trends.update_layout(height=500)\n",
    "            fig_trends.show()\n",
    "\n",
    "# ## 11. Advanced Statistical Analysis\n",
    "\n",
    "print(f\"\\nüìä ADVANCED STATISTICAL INSIGHTS:\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Emissions concentration analysis\n",
    "total_emissions = df['emissions'].sum()\n",
    "country_emissions = df.groupby('country')['emissions'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(f\"üìà CONCENTRATION METRICS:\")\n",
    "print(f\"  ‚Ä¢ Top 10 countries account for {(country_emissions.head(10).sum() / total_emissions * 100):.1f}% of emissions\")\n",
    "print(f\"  ‚Ä¢ Top 5 countries account for {(country_emissions.head(5).sum() / total_emissions * 100):.1f}% of emissions\")\n",
    "print(f\"  ‚Ä¢ Top country ({country_emissions.index[0]}) accounts for {(country_emissions.iloc[0] / total_emissions * 100):.1f}% of emissions\")\n",
    "\n",
    "# Regional analysis\n",
    "regional_stats = df.groupby('region')['emissions'].agg(['sum', 'mean', 'std', 'count'])\n",
    "print(f\"\\nüåç REGIONAL STATISTICS:\")\n",
    "for region in regional_stats.index:\n",
    "    stats = regional_stats.loc[region]\n",
    "    print(f\"  ‚Ä¢ {region}:\")\n",
    "    print(f\"    - Total: {stats['sum']:.1f} Mt CO‚ÇÇe ({stats['sum']/total_emissions*100:.1f}%)\")\n",
    "    print(f\"    - Average: {stats['mean']:.1f} Mt CO‚ÇÇe\")\n",
    "    print(f\"    - Std Dev: {stats['std']:.1f}\")\n",
    "    print(f\"    - Records: {int(stats['count'])}\")\n",
    "\n",
    "# Sector analysis\n",
    "sector_stats = df.groupby('type')['emissions'].agg(['sum', 'mean', 'std', 'count'])\n",
    "print(f\"\\nüè≠ SECTOR STATISTICS:\")\n",
    "for sector in sector_stats.index:\n",
    "    stats = sector_stats.loc[sector]\n",
    "    print(f\"  ‚Ä¢ {sector}:\")\n",
    "    print(f\"    - Total: {stats['sum']:.1f} Mt CO‚ÇÇe ({stats['sum']/total_emissions*100:.1f}%)\")\n",
    "    print(f\"    - Average: {stats['mean']:.1f} Mt CO‚ÇÇe\")\n",
    "    print(f\"    - Records: {int(stats['count'])}\")\n",
    "\n",
    "# ## 12. Data Quality and Completeness Report\n",
    "\n",
    "print(f\"\\n‚úÖ DATA QUALITY REPORT:\")\n",
    "print(\"=\"*35)\n",
    "\n",
    "quality_metrics = {\n",
    "    'Total Records': len(df),\n",
    "    'Complete Records': len(df.dropna()),\n",
    "    'Completeness Rate': f\"{(len(df.dropna()) / len(df) * 100):.1f}%\",\n",
    "    'Unique Countries': df['country'].nunique(),\n",
    "    'Unique Regions': df['region'].nunique(),\n",
    "    'Unique Sectors': df['type'].nunique(),\n",
    "    'Emission Range': f\"{df['emissions'].min():.1f} - {df['emissions'].max():.1f} Mt CO‚ÇÇe\",\n",
    "    'Average Emission': f\"{df['emissions'].mean():.1f} Mt CO‚ÇÇe\"\n",
    "}\n",
    "\n",
    "for metric, value in quality_metrics.items():\n",
    "    print(f\"  ‚Ä¢ {metric}: {value}\")\n",
    "\n",
    "# ## 13. Key Findings and Insights\n",
    "\n",
    "print(f\"\\nüéØ KEY FINDINGS:\")\n",
    "print(\"=\"*20)\n",
    "\n",
    "findings = [\n",
    "    f\"Dataset contains {len(df)} records across {df['country'].nunique()} countries\",\n",
    "    f\"{'Agriculture' if df.groupby('type')['emissions'].sum().idxmax() == 'Agriculture' else df.groupby('type')['emissions'].sum().idxmax()} sector dominates with {df.groupby('type')['emissions'].sum().max():.1f} Mt CO‚ÇÇe\",\n",
    "    f\"{df.groupby('region')['emissions'].sum().idxmax()} region leads in total emissions\",\n",
    "    f\"Top emitter is {df.groupby('country')['emissions'].sum().idxmax()} with {df.groupby('country')['emissions'].sum().max():.1f} Mt CO‚ÇÇe\",\n",
    "    f\"Emissions show {'high' if df['emissions'].std() / df['emissions'].mean() > 1 else 'moderate'} variability (CV: {df['emissions'].std() / df['emissions'].mean():.2f})\",\n",
    "    f\"Data quality is {'excellent' if len(df.dropna()) / len(df) > 0.95 else 'good' if len(df.dropna()) / len(df) > 0.8 else 'moderate'} with {len(df.dropna()) / len(df) * 100:.1f}% completeness\"\n",
    "]\n",
    "\n",
    "for i, finding in enumerate(findings, 1):\n",
    "    print(f\"  {i}. {finding}\")\n",
    "\n",
    "print(f\"\\nüîÑ NEXT STEPS:\")\n",
    "print(\"=\"*15)\n",
    "print(\"  1. Data cleaning and preprocessing\")\n",
    "print(\"  2. Feature engineering and transformation\")\n",
    "print(\"  3. Statistical analysis and hypothesis testing\")\n",
    "print(\"  4. Visualization and dashboard development\")\n",
    "print(\"  5. Predictive modeling and forecasting\")\n",
    "\n",
    "print(f\"\\n‚ú® EXPLORATION COMPLETE!\")\n",
    "print(\"=\"*25)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
