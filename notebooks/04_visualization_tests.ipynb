{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d6cbe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Greenhouse Gas Analytics - Visualization Tests\n",
    "# Notebook 04: Advanced Visualization Development and Testing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Additional libraries for advanced visualizations\n",
    "import networkx as nx\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "print(\"ðŸŽ¨ Greenhouse Gas Analytics - Visualization Tests\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Set up plotting parameters\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ## 1. Load and Prepare Data\n",
    "\n",
    "@st.cache_data\n",
    "def load_test_data():\n",
    "    \"\"\"Load data for visualization testing\"\"\"\n",
    "    try:\n",
    "        df = pd.read_parquet('../data/processed/cleaned_data.parquet')\n",
    "        print(\"âœ… Processed data loaded successfully!\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(\"âš ï¸ Creating comprehensive sample data for visualization testing...\")\n",
    "        return create_enhanced_sample_data()\n",
    "\n",
    "def create_enhanced_sample_data():\n",
    "    \"\"\"Create rich sample data for testing various visualizations\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Enhanced country data with more attributes\n",
    "    countries_data = {\n",
    "        'China': {'region': 'Asia', 'pop': 1400, 'gdp': 17734, 'dev_level': 'Developing', 'lat': 35.0, 'lon': 105.0},\n",
    "        'India': {'region': 'Asia', 'pop': 1380, 'gdp': 3737, 'dev_level': 'Developing', 'lat': 20.0, 'lon': 77.0},\n",
    "        'United States': {'region': 'North America', 'pop': 330, 'gdp': 63544, 'dev_level': 'Developed', 'lat': 40.0, 'lon': -100.0},\n",
    "        'Indonesia': {'region': 'Asia', 'pop': 270, 'gdp': 4256, 'dev_level': 'Developing', 'lat': -5.0, 'lon': 120.0},\n",
    "        'Brazil': {'region': 'South America', 'pop': 215, 'gdp': 8897, 'dev_level': 'Developing', 'lat': -14.0, 'lon': -51.0},\n",
    "        'Nigeria': {'region': 'Africa', 'pop': 220, 'gdp': 2229, 'dev_level': 'Developing', 'lat': 9.0, 'lon': 8.0},\n",
    "        'Russia': {'region': 'Europe', 'pop': 145, 'gdp': 11305, 'dev_level': 'Developed', 'lat': 60.0, 'lon': 100.0},\n",
    "        'Mexico': {'region': 'North America', 'pop': 130, 'gdp': 9946, 'dev_level': 'Developing', 'lat': 23.0, 'lon': -102.0},\n",
    "        'Iran': {'region': 'Asia', 'pop': 85, 'gdp': 5627, 'dev_level': 'Developing', 'lat': 32.0, 'lon': 53.0},\n",
    "        'Germany': {'region': 'Europe', 'pop': 83, 'gdp': 46259, 'dev_level': 'Developed', 'lat': 51.0, 'lon': 9.0},\n",
    "        'Turkey': {'region': 'Europe', 'pop': 85, 'gdp': 9127, 'dev_level': 'Developing', 'lat': 39.0, 'lon': 35.0},\n",
    "        'Canada': {'region': 'North America', 'pop': 38, 'gdp': 43242, 'dev_level': 'Developed', 'lat': 60.0, 'lon': -95.0},\n",
    "        'Australia': {'region': 'Oceania', 'pop': 26, 'gdp': 54907, 'dev_level': 'Developed', 'lat': -25.0, 'lon': 133.0},\n",
    "        'Argentina': {'region': 'South America', 'pop': 45, 'gdp': 8449, 'dev_level': 'Developing', 'lat': -38.0, 'lon': -64.0},\n",
    "        'Saudi Arabia': {'region': 'Asia', 'pop': 35, 'gdp': 23139, 'dev_level': 'Developed', 'lat': 24.0, 'lon': 45.0},\n",
    "    }\n",
    "    \n",
    "    emission_types = ['Agriculture', 'Energy', 'Waste', 'Other']\n",
    "    segments = ['Livestock', 'Oil & Gas', 'Landfills', 'Rice Cultivation', 'Coal Mining', 'Bioenergy', 'Gas pipelines']\n",
    "    \n",
    "    data = []\n",
    "    for country, info in countries_data.items():\n",
    "        # Generate emissions based on country characteristics\n",
    "        base_emission_factor = (info['pop'] / 100) + (info['gdp'] / 10000)\n",
    "        \n",
    "        for year in [2019, 2020, 2021, 2022]:\n",
    "            for emission_type in emission_types:\n",
    "                for segment in np.random.choice(segments, size=np.random.randint(2, 5), replace=False):\n",
    "                    \n",
    "                    # Sector-specific emission patterns\n",
    "                    sector_multipliers = {\n",
    "                        'Agriculture': 1.5 if info['dev_level'] == 'Developing' else 0.8,\n",
    "                        'Energy': 2.0 if info['dev_level'] == 'Developed' else 1.2,\n",
    "                        'Waste': 0.7,\n",
    "                        'Other': 0.5\n",
    "                    }\n",
    "                    \n",
    "                    emission_value = max(0, base_emission_factor * sector_multipliers[emission_type] * \n",
    "                                       np.random.uniform(0.3, 2.5) + np.random.normal(0, 10))\n",
    "                    \n",
    "                    data.append({\n",
    "                        'country': country,\n",
    "                        'region': info['region'],\n",
    "                        'population': info['pop'],\n",
    "                        'gdp_per_capita': info['gdp'],\n",
    "                        'development_level': info['dev_level'],\n",
    "                        'latitude': info['lat'],\n",
    "                        'longitude': info['lon'],\n",
    "                        'type': emission_type,\n",
    "                        'segment': segment,\n",
    "                        'emissions': emission_value,\n",
    "                        'year': year,\n",
    "                        'quarter': np.random.choice(['Q1', 'Q2', 'Q3', 'Q4']),\n",
    "                        'confidence_level': np.random.choice(['High', 'Medium', 'Low'], p=[0.6, 0.3, 0.1])\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load data\n",
    "df = load_test_data()\n",
    "\n",
    "print(f\"ðŸ“Š Dataset loaded for visualization testing:\")\n",
    "print(f\"  â€¢ Shape: {df.shape}\")\n",
    "print(f\"  â€¢ Columns: {list(df.columns)}\")\n",
    "print(f\"  â€¢ Date range: {df['year'].min()}-{df['year'].max()}\")\n",
    "\n",
    "# ## 2. Basic Visualization Tests\n",
    "\n",
    "def test_basic_plots(df):\n",
    "    \"\"\"Test basic plotting functionality\"\"\"\n",
    "    print(f\"\\nðŸ“Š TESTING BASIC VISUALIZATIONS:\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Create a comprehensive figure with subplots\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(18, 15))\n",
    "    fig.suptitle('Basic Visualization Tests', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Emissions distribution histogram\n",
    "    df['emissions'].hist(bins=50, ax=axes[0,0], alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0,0].set_title('Emissions Distribution')\n",
    "    axes[0,0].set_xlabel('Emissions (Mt COâ‚‚e)')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Regional emissions bar plot\n",
    "    regional_emissions = df.groupby('region')['emissions'].sum().sort_values(ascending=True)\n",
    "    regional_emissions.plot(kind='barh', ax=axes[0,1], color='lightcoral')\n",
    "    axes[0,1].set_title('Total Emissions by Region')\n",
    "    axes[0,1].set_xlabel('Total Emissions (Mt COâ‚‚e)')\n",
    "    \n",
    "    # 3. Parallel Coordinates Plot\n",
    "    if all(col in df.columns for col in ['emissions', 'population', 'gdp_per_capita']):\n",
    "        country_data = df.groupby('country').agg({\n",
    "            'emissions': 'sum',\n",
    "            'population': 'first',\n",
    "            'gdp_per_capita': 'first',\n",
    "            'region': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Normalize data for parallel coordinates\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        numeric_cols = ['emissions', 'population', 'gdp_per_capita']\n",
    "        country_data_scaled = country_data.copy()\n",
    "        country_data_scaled[numeric_cols] = scaler.fit_transform(country_data[numeric_cols])\n",
    "        \n",
    "        fig_parallel = px.parallel_coordinates(\n",
    "            country_data_scaled,\n",
    "            dimensions=['emissions', 'population', 'gdp_per_capita'],\n",
    "            color='emissions',\n",
    "            color_continuous_scale='Viridis',\n",
    "            title='Parallel Coordinates: Country Characteristics'\n",
    "        )\n",
    "        \n",
    "        fig_parallel.show()\n",
    "        print(\"âœ… Parallel coordinates plot created\")\n",
    "    \n",
    "    # 4. Hierarchical Treemap\n",
    "    treemap_data = df.groupby(['region', 'country', 'type'])['emissions'].sum().reset_index()\n",
    "    treemap_data = treemap_data[treemap_data['emissions'] > 0]\n",
    "    \n",
    "    fig_treemap = px.treemap(\n",
    "        treemap_data,\n",
    "        path=['region', 'country', 'type'],\n",
    "        values='emissions',\n",
    "        title='Hierarchical Emissions Breakdown: Region â†’ Country â†’ Sector',\n",
    "        color='emissions',\n",
    "        color_continuous_scale='RdYlBu_r'\n",
    "    )\n",
    "    \n",
    "    fig_treemap.update_layout(height=700)\n",
    "    fig_treemap.show()\n",
    "    print(\"âœ… Hierarchical treemap created\")\n",
    "    \n",
    "    # 5. Geographic Bubble Map\n",
    "    if all(col in df.columns for col in ['latitude', 'longitude']):\n",
    "        geo_data = df.groupby('country').agg({\n",
    "            'emissions': 'sum',\n",
    "            'latitude': 'first',\n",
    "            'longitude': 'first',\n",
    "            'region': 'first',\n",
    "            'population': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        fig_geo = px.scatter_geo(\n",
    "            geo_data,\n",
    "            lat='latitude',\n",
    "            lon='longitude',\n",
    "            size='emissions',\n",
    "            color='region',\n",
    "            hover_name='country',\n",
    "            hover_data={'emissions': ':,.1f', 'population': ':,'},\n",
    "            title='Global Emissions Distribution',\n",
    "            size_max=50\n",
    "        )\n",
    "        \n",
    "        fig_geo.update_layout(height=600)\n",
    "        fig_geo.show()\n",
    "        print(\"âœ… Geographic bubble map created\")\n",
    "    \n",
    "    # 6. Multi-panel Dashboard\n",
    "    fig_dashboard = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Regional Emissions', 'Sector Distribution', \n",
    "                       'Top Countries', 'Yearly Trends'),\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}],\n",
    "               [{\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
    "    )\n",
    "    \n",
    "    # Regional emissions\n",
    "    regional_totals = df.groupby('region')['emissions'].sum()\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Bar(x=regional_totals.index, y=regional_totals.values, name=\"Regional\"),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Sector pie\n",
    "    sector_totals = df.groupby('type')['emissions'].sum()\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Pie(labels=sector_totals.index, values=sector_totals.values, name=\"Sectors\"),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Top countries\n",
    "    top_countries = df.groupby('country')['emissions'].sum().sort_values(ascending=False).head(10)\n",
    "    fig_dashboard.add_trace(\n",
    "        go.Bar(x=top_countries.values, y=top_countries.index, \n",
    "               orientation='h', name=\"Top Countries\"),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Yearly trends\n",
    "    if 'year' in df.columns:\n",
    "        yearly_totals = df.groupby('year')['emissions'].sum()\n",
    "        fig_dashboard.add_trace(\n",
    "            go.Scatter(x=yearly_totals.index, y=yearly_totals.values, \n",
    "                      mode='lines+markers', name=\"Yearly\"),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    \n",
    "    fig_dashboard.update_layout(height=800, showlegend=False, \n",
    "                               title_text=\"Methane Emissions Dashboard\")\n",
    "    fig_dashboard.show()\n",
    "    print(\"âœ… Multi-panel dashboard created\")\n",
    "\n",
    "test_plotly_advanced(df)\n",
    "\n",
    "# ## 4. Specialized Visualizations\n",
    "\n",
    "def test_specialized_visualizations(df):\n",
    "    \"\"\"Test specialized and custom visualizations\"\"\"\n",
    "    print(f\"\\nðŸŽ¯ TESTING SPECIALIZED VISUALIZATIONS:\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    # 1. Correlation Heatmap with Clustering\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 2:\n",
    "        corr_matrix = df[numeric_cols].corr()\n",
    "        \n",
    "        # Create a mask for the upper triangle\n",
    "        mask = np.triu(np.ones_like(corr_matrix))\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,\n",
    "                   square=True, linewidths=.5, cbar_kws={\"shrink\": .8})\n",
    "        plt.title('Correlation Matrix of Numerical Variables', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"âœ… Correlation heatmap created\")\n",
    "    \n",
    "    # 2. Ridge Plot for Emissions Distribution by Region\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    regions = df['region'].unique()\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, len(regions)))\n",
    "    \n",
    "    for i, region in enumerate(regions):\n",
    "        region_emissions = df[df['region'] == region]['emissions']\n",
    "        density = region_emissions.plot.kde()\n",
    "        plt.fill_between(density.get_xdata(), density.get_ydata() + i, \n",
    "                        i, alpha=0.7, color=colors[i], label=region)\n",
    "    \n",
    "    plt.title('Emissions Distribution Ridge Plot by Region', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Emissions (Mt COâ‚‚e)')\n",
    "    plt.ylabel('Region (offset)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"âœ… Ridge plot created\")\n",
    "    \n",
    "    # 3. Radar Chart for Regional Characteristics\n",
    "    if all(col in df.columns for col in ['population', 'gdp_per_capita']):\n",
    "        regional_stats = df.groupby('region').agg({\n",
    "            'emissions': 'sum',\n",
    "            'population': 'sum',\n",
    "            'gdp_per_capita': 'mean',\n",
    "            'country': 'nunique'\n",
    "        })\n",
    "        \n",
    "        # Normalize for radar chart\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        regional_stats_norm = pd.DataFrame(\n",
    "            scaler.fit_transform(regional_stats),\n",
    "            index=regional_stats.index,\n",
    "            columns=regional_stats.columns\n",
    "        )\n",
    "        \n",
    "        fig_radar = go.Figure()\n",
    "        \n",
    "        for region in regional_stats_norm.index:\n",
    "            fig_radar.add_trace(go.Scatterpolar(\n",
    "                r=regional_stats_norm.loc[region].values.tolist() + [regional_stats_norm.loc[region].values[0]],\n",
    "                theta=list(regional_stats_norm.columns) + [regional_stats_norm.columns[0]],\n",
    "                fill='toself',\n",
    "                name=region\n",
    "            ))\n",
    "        \n",
    "        fig_radar.update_layout(\n",
    "            polar=dict(\n",
    "                radialaxis=dict(\n",
    "                    visible=True,\n",
    "                    range=[0, 1]\n",
    "                )),\n",
    "            showlegend=True,\n",
    "            title=\"Regional Characteristics Radar Chart\",\n",
    "            height=600\n",
    "        )\n",
    "        \n",
    "        fig_radar.show()\n",
    "        print(\"âœ… Radar chart created\")\n",
    "    \n",
    "    # 4. Network Graph for Country-Sector Relationships\n",
    "    # Create a network showing strongest country-sector relationships\n",
    "    country_sector = df.groupby(['country', 'type'])['emissions'].sum().reset_index()\n",
    "    country_sector = country_sector.sort_values('emissions', ascending=False).head(30)\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes\n",
    "    for country in country_sector['country'].unique():\n",
    "        G.add_node(country, node_type='country', size=20)\n",
    "    \n",
    "    for sector in country_sector['type'].unique():\n",
    "        G.add_node(sector, node_type='sector', size=15)\n",
    "    \n",
    "    # Add edges (relationships)\n",
    "    for _, row in country_sector.iterrows():\n",
    "        G.add_edge(row['country'], row['type'], weight=row['emissions'])\n",
    "    \n",
    "    plt.figure(figsize=(16, 12))\n",
    "    pos = nx.spring_layout(G, k=3, iterations=50)\n",
    "    \n",
    "    # Draw country nodes\n",
    "    country_nodes = [n for n in G.nodes() if G.nodes[n]['node_type'] == 'country']\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=country_nodes, node_color='lightblue', \n",
    "                          node_size=800, alpha=0.8)\n",
    "    \n",
    "    # Draw sector nodes\n",
    "    sector_nodes = [n for n in G.nodes() if G.nodes[n]['node_type'] == 'sector']\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=sector_nodes, node_color='lightcoral', \n",
    "                          node_size=600, alpha=0.8)\n",
    "    \n",
    "    # Draw edges with varying thickness\n",
    "    edges = G.edges(data=True)\n",
    "    weights = [edge[2]['weight'] for edge in edges]\n",
    "    nx.draw_networkx_edges(G, pos, width=[w/max(weights)*5 for w in weights], alpha=0.6)\n",
    "    \n",
    "    # Draw labels\n",
    "    nx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold')\n",
    "    \n",
    "    plt.title('Country-Sector Relationship Network', fontsize=16, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"âœ… Network graph created\")\n",
    "    \n",
    "    # 5. Sankey Diagram for Flow Analysis\n",
    "    # Create a Sankey diagram showing flow from regions to sectors\n",
    "    region_sector = df.groupby(['region', 'type'])['emissions'].sum().reset_index()\n",
    "    region_sector = region_sector[region_sector['emissions'] > 0]\n",
    "    \n",
    "    # Prepare data for Sankey\n",
    "    all_nodes = list(region_sector['region'].unique()) + list(region_sector['type'].unique())\n",
    "    node_dict = {node: i for i, node in enumerate(all_nodes)}\n",
    "    \n",
    "    sources = [node_dict[region] for region in region_sector['region']]\n",
    "    targets = [node_dict[sector] for sector in region_sector['type']]\n",
    "    values = region_sector['emissions'].tolist()\n",
    "    \n",
    "    fig_sankey = go.Figure(data=[go.Sankey(\n",
    "        node=dict(\n",
    "            pad=15,\n",
    "            thickness=20,\n",
    "            line=dict(color=\"black\", width=0.5),\n",
    "            label=all_nodes,\n",
    "            color=[\"lightblue\"]*len(region_sector['region'].unique()) + \n",
    "                  [\"lightcoral\"]*len(region_sector['type'].unique())\n",
    "        ),\n",
    "        link=dict(\n",
    "            source=sources,\n",
    "            target=targets,\n",
    "            value=values\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    fig_sankey.update_layout(\n",
    "        title_text=\"Emissions Flow: Regions to Sectors\",\n",
    "        font_size=12,\n",
    "        height=600\n",
    "    )\n",
    "    fig_sankey.show()\n",
    "    print(\"âœ… Sankey diagram created\")\n",
    "\n",
    "test_specialized_visualizations(df)\n",
    "\n",
    "# ## 5. Statistical Visualization Tests\n",
    "\n",
    "def test_statistical_plots(df):\n",
    "    \"\"\"Test statistical and analytical visualizations\"\"\"\n",
    "    print(f\"\\nðŸ“Š TESTING STATISTICAL VISUALIZATIONS:\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    # 1. Distribution Comparison with Statistical Tests\n",
    "    if 'development_level' in df.columns:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        fig.suptitle('Statistical Analysis Visualizations', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Violin plots\n",
    "        sns.violinplot(data=df, x='development_level', y='emissions', ax=axes[0,0])\n",
    "        axes[0,0].set_title('Emissions Distribution by Development Level')\n",
    "        axes[0,0].set_ylabel('Emissions (Mt COâ‚‚e)')\n",
    "        \n",
    "        # Box plots with outliers\n",
    "        sns.boxplot(data=df, x='region', y='emissions', ax=axes[0,1])\n",
    "        axes[0,1].set_title('Regional Emissions with Outliers')\n",
    "        axes[0,1].set_ylabel('Emissions (Mt COâ‚‚e)')\n",
    "        plt.setp(axes[0,1].get_xticklabels(), rotation=45)\n",
    "        \n",
    "        # Q-Q plot for normality testing\n",
    "        from scipy import stats\n",
    "        emissions_sample = df['emissions'].dropna().sample(min(1000, len(df))).sort_values()\n",
    "        stats.probplot(emissions_sample, dist=\"norm\", plot=axes[1,0])\n",
    "        axes[1,0].set_title('Q-Q Plot: Normality Test for Emissions')\n",
    "        \n",
    "        # Residual plot (using a simple linear model)\n",
    "        if 'population' in df.columns:\n",
    "            from sklearn.linear_model import LinearRegression\n",
    "            \n",
    "            country_data = df.groupby('country').agg({\n",
    "                'emissions': 'sum',\n",
    "                'population': 'first'\n",
    "            }).dropna()\n",
    "            \n",
    "            X = country_data[['population']]\n",
    "            y = country_data['emissions']\n",
    "            \n",
    "            model = LinearRegression().fit(X, y)\n",
    "            predicted = model.predict(X)\n",
    "            residuals = y - predicted\n",
    "            \n",
    "            axes[1,1].scatter(predicted, residuals, alpha=0.6)\n",
    "            axes[1,1].axhline(y=0, color='red', linestyle='--')\n",
    "            axes[1,1].set_xlabel('Predicted Emissions')\n",
    "            axes[1,1].set_ylabel('Residuals')\n",
    "            axes[1,1].set_title('Residual Plot: Population vs Emissions')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"âœ… Statistical plots created\")\n",
    "    \n",
    "    # 2. Confidence Intervals Visualization\n",
    "    if 'year' in df.columns:\n",
    "        yearly_stats = df.groupby('year')['emissions'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        yearly_stats['se'] = yearly_stats['std'] / np.sqrt(yearly_stats['count'])\n",
    "        yearly_stats['ci_lower'] = yearly_stats['mean'] - 1.96 * yearly_stats['se']\n",
    "        yearly_stats['ci_upper'] = yearly_stats['mean'] + 1.96 * yearly_stats['se']\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(yearly_stats['year'], yearly_stats['mean'], 'o-', linewidth=2, markersize=8)\n",
    "        plt.fill_between(yearly_stats['year'], yearly_stats['ci_lower'], yearly_stats['ci_upper'], \n",
    "                        alpha=0.3, label='95% Confidence Interval')\n",
    "        plt.title('Mean Emissions Over Time with Confidence Intervals', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Mean Emissions (Mt COâ‚‚e)')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"âœ… Confidence interval plot created\")\n",
    "    \n",
    "    # 3. Principal Component Analysis Visualization\n",
    "    numeric_features = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_features) > 3:\n",
    "        from sklearn.decomposition import PCA\n",
    "        \n",
    "        # Prepare data\n",
    "        pca_data = df[numeric_features].dropna()\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(pca_data)\n",
    "        \n",
    "        # Perform PCA\n",
    "        pca = PCA()\n",
    "        pca_result = pca.fit_transform(scaled_data)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Scree plot\n",
    "        explained_variance = pca.explained_variance_ratio_\n",
    "        axes[0].bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7)\n",
    "        axes[0].plot(range(1, len(explained_variance) + 1), explained_variance, 'ro-')\n",
    "        axes[0].set_xlabel('Principal Component')\n",
    "        axes[0].set_ylabel('Explained Variance Ratio')\n",
    "        axes[0].set_title('PCA Scree Plot')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # PCA biplot\n",
    "        if len(pca_result) > 0:\n",
    "            axes[1].scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.6, s=30)\n",
    "            axes[1].set_xlabel(f'PC1 ({explained_variance[0]:.1%} variance)')\n",
    "            axes[1].set_ylabel(f'PC2 ({explained_variance[1]:.1%} variance)')\n",
    "            axes[1].set_title('PCA Biplot (First Two Components)')\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"âœ… PCA visualization created\")\n",
    "\n",
    "test_statistical_plots(df)\n",
    "\n",
    "# ## 6. Interactive Dashboard Components\n",
    "\n",
    "def test_dashboard_components(df):\n",
    "    \"\"\"Test interactive dashboard components\"\"\"\n",
    "    print(f\"\\nðŸŽ›ï¸ TESTING DASHBOARD COMPONENTS:\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # 1. Filter-responsive visualization\n",
    "    def create_filtered_viz(region_filter=None, sector_filter=None):\n",
    "        \"\"\"Create visualization with filters applied\"\"\"\n",
    "        filtered_df = df.copy()\n",
    "        \n",
    "        if region_filter:\n",
    "            filtered_df = filtered_df[filtered_df['region'].isin(region_filter)]\n",
    "        if sector_filter:\n",
    "            filtered_df = filtered_df[filtered_df['type'].isin(sector_filter)]\n",
    "        \n",
    "        return filtered_df.groupby('country')['emissions'].sum().sort_values(ascending=False).head(10)\n",
    "    \n",
    "    # Test different filter combinations\n",
    "    print(\"Testing filter combinations:\")\n",
    "    \n",
    "    # All regions, Energy sector only\n",
    "    energy_only = create_filtered_viz(sector_filter=['Energy'])\n",
    "    print(f\"  â€¢ Energy sector top emitters: {list(energy_only.head(3).index)}\")\n",
    "    \n",
    "    # Asia region only\n",
    "    asia_only = create_filtered_viz(region_filter=['Asia'])\n",
    "    print(f\"  â€¢ Asia top emitters: {list(asia_only.head(3).index)}\")\n",
    "    \n",
    "    # 2. Responsive metric cards\n",
    "    def calculate_metrics(df_subset):\n",
    "        \"\"\"Calculate key metrics for any data subset\"\"\"\n",
    "        return {\n",
    "            'total_emissions': df_subset['emissions'].sum(),\n",
    "            'avg_emissions': df_subset['emissions'].mean(),\n",
    "            'num_countries': df_subset['country'].nunique(),\n",
    "            'top_sector': df_subset.groupby('type')['emissions'].sum().idxmax()\n",
    "        }\n",
    "    \n",
    "    # Test metric calculations\n",
    "    full_metrics = calculate_metrics(df)\n",
    "    asia_metrics = calculate_metrics(df[df['region'] == 'Asia'])\n",
    "    \n",
    "    print(f\"\\nMetric comparison:\")\n",
    "    print(f\"  â€¢ Global total: {full_metrics['total_emissions']:.0f} Mt\")\n",
    "    print(f\"  â€¢ Asia total: {asia_metrics['total_emissions']:.0f} Mt\")\n",
    "    print(f\"  â€¢ Asia percentage: {(asia_metrics['total_emissions']/full_metrics['total_emissions']*100):.1f}%\")\n",
    "    \n",
    "    # 3. Dynamic chart updating test\n",
    "    def create_dynamic_chart_data(time_period='all'):\n",
    "        \"\"\"Simulate dynamic data for different time periods\"\"\"\n",
    "        if time_period == 'recent' and 'year' in df.columns:\n",
    "            recent_year = df['year'].max()\n",
    "            return df[df['year'] == recent_year]\n",
    "        elif time_period == 'historical' and 'year' in df.columns:\n",
    "            historical_year = df['year'].min()\n",
    "            return df[df['year'] == historical_year]\n",
    "        else:\n",
    "            return df\n",
    "    \n",
    "    # Test dynamic data updates\n",
    "    recent_data = create_dynamic_chart_data('recent')\n",
    "    historical_data = create_dynamic_chart_data('historical')\n",
    "    \n",
    "    print(f\"\\nDynamic data test:\")\n",
    "    print(f\"  â€¢ Recent period records: {len(recent_data)}\")\n",
    "    print(f\"  â€¢ Historical period records: {len(historical_data)}\")\n",
    "    \n",
    "    print(\"âœ… Dashboard components tested successfully!\")\n",
    "\n",
    "test_dashboard_components(df)\n",
    "\n",
    "# ## 7. Performance and Optimization Tests\n",
    "\n",
    "def test_visualization_performance(df):\n",
    "    \"\"\"Test visualization performance and optimization\"\"\"\n",
    "    print(f\"\\nâš¡ TESTING VISUALIZATION PERFORMANCE:\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    performance_results = {}\n",
    "    \n",
    "    # 1. Large dataset handling\n",
    "    print(\"Testing large dataset visualization...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a large sample\n",
    "    large_sample = df.sample(n=min(10000, len(df)), replace=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(large_sample['emissions'], range(len(large_sample)), \n",
    "               alpha=0.3, s=1)\n",
    "    plt.title(f'Large Dataset Test ({len(large_sample)} points)')\n",
    "    plt.xlabel('Emissions')\n",
    "    plt.ylabel('Record Index')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    large_dataset_time = time.time() - start_time\n",
    "    performance_results['large_dataset'] = large_dataset_time\n",
    "    \n",
    "    # 2. Complex aggregation performance\n",
    "    print(\"Testing complex aggregation performance...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    complex_agg = df.groupby(['region', 'country', 'type', 'year'])['emissions'].agg([\n",
    "        'sum', 'mean', 'std', 'count', 'min', 'max'\n",
    "    ]).reset_index()\n",
    "    \n",
    "    aggregation_time = time.time() - start_time\n",
    "    performance_results['aggregation'] = aggregation_time\n",
    "    \n",
    "    # 3. Memory usage test\n",
    "    import psutil\n",
    "    import os\n",
    "    \n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_before = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    \n",
    "    # Create memory-intensive visualization\n",
    "    correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Memory Usage Test - Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    memory_after = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    memory_used = memory_after - memory_before\n",
    "    \n",
    "    performance_results['memory_usage'] = memory_used\n",
    "    \n",
    "    # Print performance results\n",
    "    print(f\"\\nðŸ“Š Performance Results:\")\n",
    "    print(f\"  â€¢ Large dataset plotting: {large_dataset_time:.2f} seconds\")\n",
    "    print(f\"  â€¢ Complex aggregation: {aggregation_time:.2f} seconds\")\n",
    "    print(f\"  â€¢ Memory usage: {memory_used:.1f} MB\")\n",
    "    \n",
    "    # Performance recommendations\n",
    "    print(f\"\\nðŸ’¡ Performance Recommendations:\")\n",
    "    if large_dataset_time > 2.0:\n",
    "        print(\"  â€¢ Consider data sampling for large datasets\")\n",
    "    if aggregation_time > 1.0:\n",
    "        print(\"  â€¢ Consider caching aggregated results\")\n",
    "    if memory_used > 100:\n",
    "        print(\"  â€¢ Consider chunking data for memory-intensive operations\")\n",
    "    \n",
    "    print(\"âœ… Performance tests completed!\")\n",
    "    \n",
    "    return performance_results\n",
    "\n",
    "performance_results = test_visualization_performance(df)\n",
    "\n",
    "# ## 8. Summary and Recommendations\n",
    "\n",
    "def generate_visualization_report(df, performance_results):\n",
    "    \"\"\"Generate comprehensive visualization testing report\"\"\"\n",
    "    print(f\"\\nðŸ“‹ VISUALIZATION TESTING REPORT:\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Dataset suitability assessment\n",
    "    data_quality_score = 0\n",
    "    \n",
    "    # Check data completeness\n",
    "    completeness = (df.count() / len(df)).mean()\n",
    "    if completeness > 0.95:\n",
    "        data_quality_score += 2\n",
    "    elif completeness > 0.8:\n",
    "        data_quality_score += 1\n",
    "    \n",
    "    # Check data diversity\n",
    "    if df['country'].nunique() > 10:\n",
    "        data_quality_score += 2\n",
    "    if df['region'].nunique() > 3:\n",
    "        data_quality_score += 1\n",
    "    if 'year' in df.columns and df['year'].nunique() > 1:\n",
    "        data_quality_score += 1\n",
    "    \n",
    "    print(f\"ðŸ“Š Data Suitability Score: {data_quality_score}/6\")\n",
    "    \n",
    "    # Visualization readiness assessment\n",
    "    viz_readiness = {\n",
    "        'Geographic visualizations': 'Ready' if 'latitude' in df.columns else 'Needs coordinates',\n",
    "        'Time series': 'Ready' if 'year' in df.columns else 'Needs temporal data',\n",
    "        'Comparative analysis': 'Ready' if df['region'].nunique() > 2 else 'Limited',\n",
    "        'Statistical analysis': 'Ready' if len(df.select_dtypes(include=[np.number]).columns) > 3 else 'Limited'\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nðŸŽ¨ Visualization Readiness:\")\n",
    "    for viz_type, status in viz_readiness.items():\n",
    "        print(f\"  â€¢ {viz_type}: {status}\")\n",
    "    \n",
    "    # Performance assessment\n",
    "    print(f\"\\nâš¡ Performance Assessment:\")\n",
    "    total_time = sum(performance_results.values())\n",
    "    if total_time < 5:\n",
    "        perf_rating = \"Excellent\"\n",
    "    elif total_time < 10:\n",
    "        perf_rating = \"Good\"\n",
    "    elif total_time < 20:\n",
    "        perf_rating = \"Fair\"\n",
    "    else:\n",
    "        perf_rating = \"Needs optimization\"\n",
    "    \n",
    "    print(f\"  â€¢ Overall performance: {perf_rating}\")\n",
    "    print(f\"  â€¢ Total processing time: {total_time:.2f} seconds\")\n",
    "    \n",
    "    # Recommended visualizations\n",
    "    recommended_viz = [\n",
    "        \"Global choropleth maps for geographic distribution\",\n",
    "        \"Time series plots for trend analysis\",\n",
    "        \"Treemaps for hierarchical sector breakdown\",\n",
    "        \"Scatter plots for correlation analysis\",\n",
    "        \"Box plots for distribution comparison\",\n",
    "        \"Sankey diagrams for flow analysis\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Recommended Visualizations:\")\n",
    "    for i, viz in enumerate(recommended_viz, 1):\n",
    "        print(f\"  {i}. {viz}\")\n",
    "    \n",
    "    # Implementation priorities\n",
    "    print(f\"\\nðŸš€ Implementation Priorities:\")\n",
    "    priorities = [\n",
    "        \"Implement responsive filtering for all charts\",\n",
    "        \"Add interactive tooltips and hover information\",\n",
    "        \"Create downloadable/exportable chart formats\",\n",
    "        \"Optimize performance for large datasets\",\n",
    "        \"Add real-time data update capabilities\"\n",
    "    ]\n",
    "    \n",
    "    for i, priority in enumerate(priorities, 1):\n",
    "        print(f\"  {i}. {priority}\")\n",
    "    \n",
    "    return {\n",
    "        'data_quality_score': data_quality_score,\n",
    "        'viz_readiness': viz_readiness,\n",
    "        'performance_rating': perf_rating,\n",
    "        'recommended_visualizations': recommended_viz\n",
    "    }\n",
    "\n",
    "# Generate final report\n",
    "viz_report = generate_visualization_report(df, performance_results)\n",
    "\n",
    "print(f\"\\nâœ¨ VISUALIZATION TESTING COMPLETE!\")\n",
    "print(\"=\"*45)\n",
    "print(f\"ðŸŽ¨ All visualization types tested successfully\")\n",
    "print(f\"ðŸ“Š Performance benchmarks established\")\n",
    "print(f\"ðŸŽ¯ Implementation roadmap created\")\n",
    "print(f\"ðŸš€ Ready for dashboard development!\") Sector pie chart\n",
    "    sector_emissions = df.groupby('type')['emissions'].sum()\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(sector_emissions)))\n",
    "    axes[1,0].pie(sector_emissions.values, labels=sector_emissions.index, autopct='%1.1f%%', colors=colors)\n",
    "    axes[1,0].set_title('Emissions by Sector')\n",
    "    \n",
    "    # 4. Scatter plot: Population vs Emissions\n",
    "    if 'population' in df.columns:\n",
    "        country_data = df.groupby('country').agg({\n",
    "            'emissions': 'sum',\n",
    "            'population': 'first',\n",
    "            'region': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        for region in country_data['region'].unique():\n",
    "            region_data = country_data[country_data['region'] == region]\n",
    "            axes[1,1].scatter(region_data['population'], region_data['emissions'], \n",
    "                            label=region, alpha=0.7, s=60)\n",
    "        \n",
    "        axes[1,1].set_xlabel('Population (millions)')\n",
    "        axes[1,1].set_ylabel('Total Emissions (Mt COâ‚‚e)')\n",
    "        axes[1,1].set_title('Population vs Emissions by Region')\n",
    "        axes[1,1].legend()\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Time series plot\n",
    "    if 'year' in df.columns:\n",
    "        yearly_emissions = df.groupby(['year', 'type'])['emissions'].sum().reset_index()\n",
    "        for emission_type in yearly_emissions['type'].unique():\n",
    "            type_data = yearly_emissions[yearly_emissions['type'] == emission_type]\n",
    "            axes[2,0].plot(type_data['year'], type_data['emissions'], \n",
    "                          marker='o', linewidth=2, label=emission_type)\n",
    "        \n",
    "        axes[2,0].set_xlabel('Year')\n",
    "        axes[2,0].set_ylabel('Emissions (Mt COâ‚‚e)')\n",
    "        axes[2,0].set_title('Emission Trends by Sector')\n",
    "        axes[2,0].legend()\n",
    "        axes[2,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Box plot by region\n",
    "    df.boxplot(column='emissions', by='region', ax=axes[2,1])\n",
    "    axes[2,1].set_title('Emissions Distribution by Region')\n",
    "    axes[2,1].set_xlabel('Region')\n",
    "    axes[2,1].set_ylabel('Emissions (Mt COâ‚‚e)')\n",
    "    plt.setp(axes[2,1].get_xticklabels(), rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… Basic plots generated successfully!\")\n",
    "\n",
    "test_basic_plots(df)\n",
    "\n",
    "# ## 3. Advanced Plotly Visualizations\n",
    "\n",
    "def test_plotly_advanced(df):\n",
    "    \"\"\"Test advanced interactive visualizations with Plotly\"\"\"\n",
    "    print(f\"\\nðŸŽ¨ TESTING ADVANCED PLOTLY VISUALIZATIONS:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. 3D Scatter Plot\n",
    "    if all(col in df.columns for col in ['population', 'gdp_per_capita', 'emissions']):\n",
    "        country_summary = df.groupby('country').agg({\n",
    "            'emissions': 'sum',\n",
    "            'population': 'first',\n",
    "            'gdp_per_capita': 'first',\n",
    "            'region': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        fig_3d = px.scatter_3d(\n",
    "            country_summary,\n",
    "            x='population',\n",
    "            y='gdp_per_capita',\n",
    "            z='emissions',\n",
    "            color='region',\n",
    "            size='emissions',\n",
    "            hover_name='country',\n",
    "            title='3D Analysis: Population, GDP per Capita, and Emissions',\n",
    "            labels={\n",
    "                'population': 'Population (millions)',\n",
    "                'gdp_per_capita': 'GDP per Capita (USD)',\n",
    "                'emissions': 'Total Emissions (Mt COâ‚‚e)'\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        fig_3d.update_layout(height=600)\n",
    "        fig_3d.show()\n",
    "        print(\"âœ… 3D scatter plot created\")\n",
    "    \n",
    "    # 2. Animated Time Series\n",
    "    if 'year' in df.columns:\n",
    "        yearly_country_data = df.groupby(['year', 'country']).agg({\n",
    "            'emissions': 'sum',\n",
    "            'population': 'first',\n",
    "            'gdp_per_capita': 'first',\n",
    "            'region': 'first'\n",
    "        }).reset_index()\n",
    "        \n",
    "        fig_animated = px.scatter(\n",
    "            yearly_country_data,\n",
    "            x='gdp_per_capita',\n",
    "            y='emissions',\n",
    "            size='population',\n",
    "            color='region',\n",
    "            hover_name='country',\n",
    "            animation_frame='year',\n",
    "            title='Animated Emissions vs GDP per Capita Over Time',\n",
    "            labels={\n",
    "                'gdp_per_capita': 'GDP per Capita (USD)',\n",
    "                'emissions': 'Total Emissions (Mt COâ‚‚e)'\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        fig_animated.update_layout(height=600)\n",
    "        fig_animated.show()\n",
    "        print(\"âœ… Animated scatter plot created\")\n",
    "    \n",
    "    # 3."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
